{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUOxuEgcq2qR1bI483CQdp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YF33Nnv2qCyh","executionInfo":{"status":"ok","timestamp":1735547081600,"user_tz":-330,"elapsed":10212,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"markdown","source":["# Importing MNIST Data From Keras.datasets module\n","The dataset includes 70,000 handwritten digits in X with respective labels in Y. The dimension of each images are 28*28 pixels which can easily handle by Feed Forward Network."],"metadata":{"id":"Q9jCeyMNqmxj"}},{"cell_type":"code","source":["(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vdeV4m4rbPa","executionInfo":{"status":"ok","timestamp":1735547360409,"user_tz":-330,"elapsed":787,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}},"outputId":"a8a618c6-5118-4eb5-b2d2-9251a5d3ba45"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["print(\"Here is the shape of images with 60000 samples: \", X_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_fXxwanrw7m","executionInfo":{"status":"ok","timestamp":1735547479979,"user_tz":-330,"elapsed":414,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}},"outputId":"8126fa1e-305e-43c6-885a-67f6c802cb6e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Here is the shape of images with 60000 samples:  (60000, 28, 28)\n"]}]},{"cell_type":"markdown","source":["# Normalizing each pixel values to be in between 0-1\n","Each pixel values are of range between 0-256 (which is pixel standard range). but to train ML model efficiently we have to compress it to between 0-1.\n","and save it from rapid weight updates on backpropagation and improve accuracy."],"metadata":{"id":"JjeMX_IvsOB-"}},{"cell_type":"code","source":["X_train = np.array(X_train)/255   # dividing each pixel values to 255 which dicreases its values range. i converted it to numpy array because numpy help to apply this compression to each value without eplicitly dividing  every matrix value one by one\n","X_test = np.array(X_test)/255"],"metadata":{"id":"oKjcWd_MtTOr","executionInfo":{"status":"ok","timestamp":1735548020914,"user_tz":-330,"elapsed":609,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(X_train[0][6:10, :])  # Here are visual representation of compressed values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-iFmj6juQU8","executionInfo":{"status":"ok","timestamp":1735548146465,"user_tz":-330,"elapsed":675,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}},"outputId":"fc013e29-6a59-4ca0-e2df-a72a575af81d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.00046136 0.00055363 0.0014456  0.00236832\n","  0.00261438 0.00389081 0.00389081 0.00389081 0.00389081 0.00389081\n","  0.00346021 0.00264514 0.00389081 0.00372165 0.00299885 0.00098424\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.00075356 0.00366013 0.00389081 0.00389081 0.00389081\n","  0.00389081 0.00389081 0.00389081 0.00389081 0.00389081 0.00386005\n","  0.00143022 0.00126105 0.00126105 0.00086121 0.00059977 0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.00027682 0.00336794 0.00389081 0.00389081 0.00389081\n","  0.00389081 0.00389081 0.00304498 0.00279892 0.00379854 0.00370627\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.0012303  0.00239908 0.00164552 0.00389081\n","  0.00389081 0.00315263 0.00016917 0.         0.00066128 0.00236832\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n"]}]},{"cell_type":"markdown","source":["# Building Model\n","building model using keras Sequential API which help to combine various neural network layer sequentially and flow data from them to train."],"metadata":{"id":"x6BuW_Pvuw2o"}},{"cell_type":"code","source":["model = tf.keras.Sequential([      # Sequential is a keras deep learning moduel which help to combine more than one nerual network layer Sequentialy\n","        tf.keras.layers.Flatten(input_shape=(28, 28)),           # Flatten layer help to flat the 28*28 dimension of image to single dimension 784 to process further\n","        tf.keras.layers.Dense(512, activation='relu'),           # here is the first layer of Nerual network which takes 784 neuron on values with their respective weights and output 512 neuron values\n","        tf.keras.layers.Dense(256, activation='relu'),           # here is the second layer of Nerual network which takes 512 neuron values with their respective weights and output 256 neuron values\n","        tf.keras.layers.Dense(128, activation='relu'),           # here is the third layer of Neural network which takes 256 neuron values with their respective weights output 128 neuron values\n","        tf.keras.layers.Dense(128, activation='softmax'),       # here is the Last layer of Neural network which takes 128 neuron values with their respective weights and output 10 predictions maked by model (values between 0 to 9)\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFsirEnLvLCj","executionInfo":{"status":"ok","timestamp":1735549339644,"user_tz":-330,"elapsed":608,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}},"outputId":"1d98d3d9-498a-45a5-c38d-5a9ee8bea7f3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}]},{"cell_type":"markdown","source":["# Compiling model:\n","because of Sequential and model.fit module is written in C++ we have to compile the architecture first with appropriate Optimizer, Loss and Accuracy\n","* Optimizer: (Update the weights on training).\n","* Loss function: (Calculates loss occured by model by comparing actual and predicted values).\n","* accuracy: (help to calculate how many % correct prediction model does)"],"metadata":{"id":"U9Q_tCPyzULV"}},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy']\n","              )"],"metadata":{"id":"Ka9iDRgb6xbY","executionInfo":{"status":"ok","timestamp":1735551416230,"user_tz":-330,"elapsed":439,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Training model using model.fit module:\n","It is written in C++ which help us to boost training backpropagation computation fastly and reducing dynamic time consuming training.\n","\n","* epochs refers to how many times model observe the whole data (to increase accuracy and robustness)\n","* batch_size refers to how many images they see at a time (To increase GPU Optimization and parallelize computation on different GPU Threads)"],"metadata":{"id":"wGq8OtH-7PNO"}},{"cell_type":"code","source":["model.fit(X_train, Y_train, epochs=5, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rX7OXxj78pXd","executionInfo":{"status":"ok","timestamp":1735551933156,"user_tz":-330,"elapsed":98712,"user":{"displayName":"Amisha Pal","userId":"12591345810242800048"}},"outputId":"da43b6b7-ba14-4385-e607-59edb1636c32"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 1.5058\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8949 - loss: 0.3462\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9244 - loss: 0.2476\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9439 - loss: 0.1832\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9556 - loss: 0.1450\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a21187dea70>"]},"metadata":{},"execution_count":11}]}]}